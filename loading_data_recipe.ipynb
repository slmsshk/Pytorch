{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Loading data in PyTorch\nPyTorch features extensive neural network building blocks with a simple,\nintuitive, and stable API. PyTorch includes packages to prepare and load\ncommon datasets for your model.\n\n## Introduction\nAt the heart of PyTorch data loading utility is the\n[torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)_\nclass. It represents a Python iterable over a dataset. Libraries in\nPyTorch offer built-in high-quality datasets for you to use in\n[torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)_.\nThese datasets are currently available in:\n\n* [torchvision](https://pytorch.org/vision/stable/datasets.html)_\n* [torchaudio](https://pytorch.org/audio/stable/datasets.html)_\n* [torchtext](https://pytorch.org/text/stable/datasets.html)_\n\nwith more to come.\nUsing the Yesno dataset from ``torchaudio.datasets.YESNO``, we will\ndemonstrate how to effectively and efficiently load data from a PyTorch\n``Dataset`` into a PyTorch ``DataLoader``.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\nBefore we begin, we need to install ``torchaudio`` to have access to the\ndataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# pip install torchaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To run in Google Colab, uncomment the following line:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# !pip install torchaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Steps\n\n1. Import all necessary libraries for loading our data\n2. Access the data in the dataset\n3. Loading the data\n4. Iterate over the data\n5. [Optional] Visualize the data\n\n\n## 1. Import necessary libraries for loading our data\n\nFor this recipe, we will use ``torch`` and ``torchaudio``. Depending on\nwhat built-in datasets you use, you can also install and import\n``torchvision`` or ``torchtext``.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torchaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Access the data in the dataset\n\nThe Yesno dataset in ``torchaudio`` features sixty recordings of one\nindividual saying yes or no in Hebrew; with each recording being eight\nwords long ([read more here](https://www.openslr.org/1/)_).\n\n``torchaudio.datasets.YESNO`` creates a dataset for YesNo.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "torchaudio.datasets.YESNO(\n     root='./',\n     url='http://www.openslr.org/resources/1/waves_yesno.tar.gz',\n     folder_in_archive='waves_yesno',\n     download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each item in the dataset is a tuple of the form: (waveform, sample_rate,\nlabels).\n\nYou must set a ``root`` for the Yesno dataset, which is where the\ntraining and testing dataset will exist. The other parameters are\noptional, with their default values shown. Here is some additional\nuseful info on the other parameters:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# * ``download``: If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.\n#\n# Let\u2019s access our Yesno data:\n#\n\n# A data point in Yesno is a tuple (waveform, sample_rate, labels) where labels\n# is a list of integers with 1 for yes and 0 for no.\nyesno_data = torchaudio.datasets.YESNO('./', download=True)\n\n# Pick data point number 3 to see an example of the the yesno_data:\nn = 3\nwaveform, sample_rate, labels = yesno_data[n]\nprint(\"Waveform: {}\\nSample rate: {}\\nLabels: {}\".format(waveform, sample_rate, labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When using this data in practice, it is best practice to provision the\ndata into a \u201ctraining\u201d dataset and a \u201ctesting\u201d dataset. This ensures\nthat you have out-of-sample data to test the performance of your model.\n\n## 3. Loading the data\n\nNow that we have access to the dataset, we must pass it through\n``torch.utils.data.DataLoader``. The ``DataLoader`` combines the dataset\nand a sampler, returning an iterable over the dataset.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_loader = torch.utils.data.DataLoader(yesno_data,\n                                          batch_size=1,\n                                          shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Iterate over the data\n\nOur data is now iterable using the ``data_loader``. This will be\nnecessary when we begin training our model! You will notice that now\neach data entry in the ``data_loader`` object is converted to a tensor\ncontaining tensors representing our waveform, sample rate, and labels.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for data in data_loader:\n  print(\"Data: \", data)\n  print(\"Waveform: {}\\nSample rate: {}\\nLabels: {}\".format(data[0], data[1], data[2]))\n  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. [Optional] Visualize the data\n\nYou can optionally visualize your data to further understand the output\nfrom your ``DataLoader``.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nprint(data[0][0].numpy())\n\nplt.figure()\nplt.plot(waveform.t().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Congratulations! You have successfully loaded data in PyTorch.\n\n## Learn More\n\nTake a look at these other recipes to continue your learning:\n\n- [Defining a Neural Network](https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html)_\n- [What is a state_dict in PyTorch](https://pytorch.org/tutorials/recipes/recipes/what_is_state_dict.html)_\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}